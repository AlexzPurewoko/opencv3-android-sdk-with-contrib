ok: class CLASS ::.Text : , name: Text, base: 

===== Common header : /Users/Chao/opencv/modules/dnn/misc/java/src/cpp/dnn_converters.hpp =====

===== Common header : /Users/Chao/opencv/modules/features2d/misc/java/src/cpp/features2d_converters.hpp =====


===== Header: /Users/Chao/opencv_contrib/modules/text/include/opencv2/text.hpp =====
Namespaces: set([])
Ignore header: /Users/Chao/opencv_contrib/modules/text/include/opencv2/text.hpp


===== Header: /Users/Chao/opencv_contrib/modules/text/include/opencv2/text/erfilter.hpp =====
Namespaces: set([u'cv.text', u'cv'])

--- Incoming ---
[   u'class cv.text.ERFilter',
    ': cv::Algorithm',
    [],
    [],
    None,
    u"@brief Base class for 1st and 2nd stages of Neumann and Matas scene text detection algorithm @cite Neumann12. :\n\nExtracts the component tree (if needed) and filter the extremal regions (ER's) by using a given classifier."]
ok: class CLASS cv.text::.ERFilter : Algorithm, name: ERFilter, base: Algorithm

--- Incoming ---
[   u'class cv.text.ERFilter.Callback',
    '',
    [],
    [],
    None,
    u'@brief Callback with the classifier is made a class.\n\nBy doing it we hide SVM, Boost etc. Developers can provide their own classifiers to the\nERFilter algorithm.']
ok: class CLASS cv.text::ERFilter.Callback : , name: Callback, base: 

--- Incoming ---
[   u'cv.text.createERFilterNM1',
    u'Ptr_ERFilter',
    [],
    [   [u'Ptr_ERFilter_Callback', u'cb', u'', ['/C', '/Ref']],
        [u'int', u'thresholdDelta', u'1', []],
        [u'float', u'minArea', u'(float)0.00025', []],
        [u'float', u'maxArea', u'(float)0.13', []],
        [u'float', u'minProbability', u'(float)0.4', []],
        [u'bool', u'nonMaxSuppression', u'true', []],
        [u'float', u'minProbabilityDiff', u'(float)0.1', []]],
    u'Ptr<ERFilter>',
    u"@brief Create an Extremal Region Filter for the 1st stage classifier of N&M algorithm @cite Neumann12.\n\n@param  cb :   Callback with the classifier. Default classifier can be implicitly load with function\nloadClassifierNM1, e.g. from file in samples/cpp/trained_classifierNM1.xml\n@param  thresholdDelta :   Threshold step in subsequent thresholds when extracting the component tree\n@param  minArea :   The minimum area (% of image size) allowed for retreived ER's\n@param  maxArea :   The maximum area (% of image size) allowed for retreived ER's\n@param  minProbability :   The minimum probability P(er|character) allowed for retreived ER's\n@param  nonMaxSuppression :   Whenever non-maximum suppression is done over the branch probabilities\n@param  minProbabilityDiff :   The minimum probability difference between local maxima and local minima ERs\n\nThe component tree of the image is extracted by a threshold increased step by step from 0 to 255,\nincrementally computable descriptors (aspect_ratio, compactness, number of holes, and number of\nhorizontal crossings) are computed for each ER and used as features for a classifier which estimates\nthe class-conditional probability P(er|character). The value of P(er|character) is tracked using the\ninclusion relation of ER across all thresholds and only the ERs which correspond to local maximum of\nthe probability P(er|character) are selected (if the local maximum of the probability is above a\nglobal limit pmin and the difference between local maximum and local minimum is greater than\nminProbabilityDiff)."]
ok: FUNC <Ptr_ERFilter cv.text..createERFilterNM1 [ARG Ptr_ERFilter_Callback cb=, ARG int thresholdDelta=1, ARG float minArea=(float)0.00025, ARG float maxArea=(float)0.13, ARG float minProbability=(float)0.4, ARG bool nonMaxSuppression=true, ARG float minProbabilityDiff=(float)0.1]>

--- Incoming ---
[   u'cv.text.createERFilterNM2',
    u'Ptr_ERFilter',
    [],
    [   [u'Ptr_ERFilter_Callback', u'cb', u'', ['/C', '/Ref']],
        [u'float', u'minProbability', u'(float)0.3', []]],
    u'Ptr<ERFilter>',
    u"@brief Create an Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12.\n\n@param  cb :   Callback with the classifier. Default classifier can be implicitly load with function\nloadClassifierNM2, e.g. from file in samples/cpp/trained_classifierNM2.xml\n@param  minProbability :   The minimum probability P(er|character) allowed for retreived ER's\n\nIn the second stage, the ERs that passed the first stage are classified into character and\nnon-character classes using more informative but also more computationally expensive features. The\nclassifier uses all the features calculated in the first stage and the following additional\nfeatures: hole area ratio, convex hull ratio, and number of outer inflexion points."]
ok: FUNC <Ptr_ERFilter cv.text..createERFilterNM2 [ARG Ptr_ERFilter_Callback cb=, ARG float minProbability=(float)0.3]>

--- Incoming ---
[   u'cv.text.createERFilterNM1',
    u'Ptr_ERFilter',
    [],
    [   [u'String', u'filename', u'', ['/C', '/Ref']],
        [u'int', u'thresholdDelta', u'1', []],
        [u'float', u'minArea', u'(float)0.00025', []],
        [u'float', u'maxArea', u'(float)0.13', []],
        [u'float', u'minProbability', u'(float)0.4', []],
        [u'bool', u'nonMaxSuppression', u'true', []],
        [u'float', u'minProbabilityDiff', u'(float)0.1', []]],
    u'Ptr<ERFilter>',
    u'@brief Reads an Extremal Region Filter for the 1st stage classifier of N&M algorithm\nfrom the provided path e.g. /path/to/cpp/trained_classifierNM1.xml\n\n@overload']
ok: FUNC <Ptr_ERFilter cv.text..createERFilterNM1 [ARG String filename=, ARG int thresholdDelta=1, ARG float minArea=(float)0.00025, ARG float maxArea=(float)0.13, ARG float minProbability=(float)0.4, ARG bool nonMaxSuppression=true, ARG float minProbabilityDiff=(float)0.1]>

--- Incoming ---
[   u'cv.text.createERFilterNM2',
    u'Ptr_ERFilter',
    [],
    [   [u'String', u'filename', u'', ['/C', '/Ref']],
        [u'float', u'minProbability', u'(float)0.3', []]],
    u'Ptr<ERFilter>',
    u'@brief Reads an Extremal Region Filter for the 2nd stage classifier of N&M algorithm\nfrom the provided path e.g. /path/to/cpp/trained_classifierNM2.xml\n\n@overload']
ok: FUNC <Ptr_ERFilter cv.text..createERFilterNM2 [ARG String filename=, ARG float minProbability=(float)0.3]>

--- Incoming ---
[   u'cv.text.loadClassifierNM1',
    u'Ptr_ERFilter_Callback',
    [],
    [[u'String', u'filename', u'', ['/C', '/Ref']]],
    u'Ptr<ERFilter::Callback>',
    u'@brief Allow to implicitly load the default classifier when creating an ERFilter object.\n\n@param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM1.xml)\n\nreturns a pointer to ERFilter::Callback.']
ok: FUNC <Ptr_ERFilter_Callback cv.text..loadClassifierNM1 [ARG String filename=]>

--- Incoming ---
[   u'cv.text.loadClassifierNM2',
    u'Ptr_ERFilter_Callback',
    [],
    [[u'String', u'filename', u'', ['/C', '/Ref']]],
    u'Ptr<ERFilter::Callback>',
    u'@brief Allow to implicitly load the default classifier when creating an ERFilter object.\n\n@param filename The XML or YAML file with the classifier model (e.g. trained_classifierNM2.xml)\n\nreturns a pointer to ERFilter::Callback.']
ok: FUNC <Ptr_ERFilter_Callback cv.text..loadClassifierNM2 [ARG String filename=]>

--- Incoming ---
[u'const cv.text.ERFILTER_NM_RGBLGrad', '0', [], [], None, '']
ok: CONST ERFILTER_NM_RGBLGrad=0

--- Incoming ---
[u'const cv.text.ERFILTER_NM_IHSGrad', '1', [], [], None, '']
ok: CONST ERFILTER_NM_IHSGrad=1

--- Incoming ---
[   u'cv.text.computeNMChannels',
    u'void',
    [],
    [   ['Mat', u'_src', '', []],
        ['vector_Mat', u'_channels', '', ['/O', '/O']],
        [u'int', u'_mode', u'ERFILTER_NM_RGBLGrad', []]],
    u'void',
    u'@brief Compute the different channels to be processed independently in the N&M algorithm @cite Neumann12.\n\n@param _src Source image. Must be RGB CV_8UC3.\n\n@param _channels Output vector\\<Mat\\> where computed channels are stored.\n\n@param _mode Mode of operation. Currently the only available options are:\n**ERFILTER_NM_RGBLGrad** (used by default) and **ERFILTER_NM_IHSGrad**.\n\nIn N&M algorithm, the combination of intensity (I), hue (H), saturation (S), and gradient magnitude\nchannels (Grad) are used in order to obtain high localization recall. This implementation also\nprovides an alternative combination of red (R), green (G), blue (B), lightness (L), and gradient\nmagnitude (Grad).']
ok: FUNC <void cv.text..computeNMChannels [ARG Mat _src=, ARG vector_Mat _channels=, ARG int _mode=ERFILTER_NM_RGBLGrad]>

--- Incoming ---
[u'const cv.text.ERGROUPING_ORIENTATION_HORIZ', '0', [], [], None, '']
ok: CONST ERGROUPING_ORIENTATION_HORIZ=0

--- Incoming ---
[u'const cv.text.ERGROUPING_ORIENTATION_ANY', '1', [], [], None, '']
ok: CONST ERGROUPING_ORIENTATION_ANY=1

--- Incoming ---
[   u'cv.text.erGrouping',
    u'void',
    [],
    [   ['Mat', u'image', '', []],
        ['Mat', u'channel', '', []],
        [u'vector_vector_Point', u'regions', u'', []],
        [u'vector_Rect', u'groups_rects', u'', ['/O', '/Ref']],
        [u'int', u'method', u'ERGROUPING_ORIENTATION_HORIZ', []],
        [u'String', u'filename', u'String()', ['/C', '/Ref']],
        [u'float', u'minProbablity', u'(float)0.5', []]],
    u'void',
    u"@brief Find groups of Extremal Regions that are organized as text blocks.\n\n@param img Original RGB or Greyscale image from wich the regions were extracted.\n\n@param channels Vector of single channel images CV_8UC1 from wich the regions were extracted.\n\n@param regions Vector of ER's retrieved from the ERFilter algorithm from each channel.\n\n@param groups The output of the algorithm is stored in this parameter as set of lists of indexes to\nprovided regions.\n\n@param groups_rects The output of the algorithm are stored in this parameter as list of rectangles.\n\n@param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ,\nERGROUPING_ORIENTATION_ANY.\n\n@param filename The XML or YAML file with the classifier model (e.g.\nsamples/trained_classifier_erGrouping.xml). Only to use when grouping method is\nERGROUPING_ORIENTATION_ANY.\n\n@param minProbablity The minimum probability for accepting a group. Only to use when grouping\nmethod is ERGROUPING_ORIENTATION_ANY."]
ok: FUNC <void cv.text..erGrouping [ARG Mat image=, ARG Mat channel=, ARG vector_vector_Point regions=, ARG vector_Rect groups_rects=, ARG int method=ERGROUPING_ORIENTATION_HORIZ, ARG String filename=String(), ARG float minProbablity=(float)0.5]>

--- Incoming ---
[   u'cv.text.detectRegions',
    u'void',
    [],
    [   ['Mat', u'image', '', []],
        [u'Ptr_ERFilter', u'er_filter1', u'', ['/C', '/Ref']],
        [u'Ptr_ERFilter', u'er_filter2', u'', ['/C', '/Ref']],
        [u'vector_vector_Point', u'regions', u'', ['/O', '/Ref']]],
    u'void',
    u'@brief Converts MSER contours (vector\\<Point\\>) to ERStat regions.\n\n@param image Source image CV_8UC1 from which the MSERs where extracted.\n\n@param contours Input vector with all the contours (vector\\<Point\\>).\n\n@param regions Output where the ERStat regions are stored.\n\nIt takes as input the contours provided by the OpenCV MSER feature detector and returns as output\ntwo vectors of ERStats. This is because MSER() output contains both MSER+ and MSER- regions in a\nsingle vector\\<Point\\>, the function separates them in two different vectors (this is as if the\nERStats where extracted from two different channels).\n\nAn example of MSERsToERStats in use can be found in the text detection webcam_demo:\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp>']
ok: FUNC <void cv.text..detectRegions [ARG Mat image=, ARG Ptr_ERFilter er_filter1=, ARG Ptr_ERFilter er_filter2=, ARG vector_vector_Point regions=]>

--- Incoming ---
[   u'cv.text.detectRegions',
    u'void',
    [],
    [   ['Mat', u'image', '', []],
        [u'Ptr_ERFilter', u'er_filter1', u'', ['/C', '/Ref']],
        [u'Ptr_ERFilter', u'er_filter2', u'', ['/C', '/Ref']],
        [u'vector_Rect', u'groups_rects', u'', ['/O', '/Ref']],
        [u'int', u'method', u'ERGROUPING_ORIENTATION_HORIZ', []],
        [u'String', u'filename', u'String()', ['/C', '/Ref']],
        [u'float', u'minProbability', u'(float)0.5', []]],
    u'void',
    u'@brief Extracts text regions from image.\n\n@param image Source image where text blocks needs to be extracted from.  Should be CV_8UC3 (color).\n@param er_filter1 Extremal Region Filter for the 1st stage classifier of N&M algorithm @cite Neumann12\n@param er_filter2 Extremal Region Filter for the 2nd stage classifier of N&M algorithm @cite Neumann12\n@param groups_rects Output list of rectangle blocks with text\n@param method Grouping method (see text::erGrouping_Modes). Can be one of ERGROUPING_ORIENTATION_HORIZ, ERGROUPING_ORIENTATION_ANY.\n@param filename The XML or YAML file with the classifier model (e.g. samples/trained_classifier_erGrouping.xml). Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.\n@param minProbability The minimum probability for accepting a group. Only to use when grouping method is ERGROUPING_ORIENTATION_ANY.']
ok: FUNC <void cv.text..detectRegions [ARG Mat image=, ARG Ptr_ERFilter er_filter1=, ARG Ptr_ERFilter er_filter2=, ARG vector_Rect groups_rects=, ARG int method=ERGROUPING_ORIENTATION_HORIZ, ARG String filename=String(), ARG float minProbability=(float)0.5]>


===== Header: /Users/Chao/opencv_contrib/modules/text/include/opencv2/text/ocr.hpp =====
Namespaces: set([u'cv.text', u'cv'])

--- Incoming ---
[u'const cv.text.OCR_LEVEL_WORD', '0', [], [], None, '']
ok: CONST OCR_LEVEL_WORD=0

--- Incoming ---
[u'const cv.text.OCR_LEVEL_TEXTLINE', '1', [], [], None, '']
ok: CONST OCR_LEVEL_TEXTLINE=1

--- Incoming ---
[u'const cv.text.PSM_OSD_ONLY', '0', [], [], None, '']
ok: CONST PSM_OSD_ONLY=0

--- Incoming ---
[u'const cv.text.PSM_AUTO_OSD', '1', [], [], None, '']
ok: CONST PSM_AUTO_OSD=1

--- Incoming ---
[u'const cv.text.PSM_AUTO_ONLY', '2', [], [], None, '']
ok: CONST PSM_AUTO_ONLY=2

--- Incoming ---
[u'const cv.text.PSM_AUTO', '3', [], [], None, '']
ok: CONST PSM_AUTO=3

--- Incoming ---
[u'const cv.text.PSM_SINGLE_COLUMN', '4', [], [], None, '']
ok: CONST PSM_SINGLE_COLUMN=4

--- Incoming ---
[u'const cv.text.PSM_SINGLE_BLOCK_VERT_TEXT', '5', [], [], None, '']
ok: CONST PSM_SINGLE_BLOCK_VERT_TEXT=5

--- Incoming ---
[u'const cv.text.PSM_SINGLE_BLOCK', '6', [], [], None, '']
ok: CONST PSM_SINGLE_BLOCK=6

--- Incoming ---
[u'const cv.text.PSM_SINGLE_LINE', '7', [], [], None, '']
ok: CONST PSM_SINGLE_LINE=7

--- Incoming ---
[u'const cv.text.PSM_SINGLE_WORD', '8', [], [], None, '']
ok: CONST PSM_SINGLE_WORD=8

--- Incoming ---
[u'const cv.text.PSM_CIRCLE_WORD', '9', [], [], None, '']
ok: CONST PSM_CIRCLE_WORD=9

--- Incoming ---
[u'const cv.text.PSM_SINGLE_CHAR', '10', [], [], None, '']
ok: CONST PSM_SINGLE_CHAR=10

--- Incoming ---
[u'const cv.text.OEM_TESSERACT_ONLY', '0', [], [], None, '']
ok: CONST OEM_TESSERACT_ONLY=0

--- Incoming ---
[u'const cv.text.OEM_CUBE_ONLY', '1', [], [], None, '']
ok: CONST OEM_CUBE_ONLY=1

--- Incoming ---
[u'const cv.text.OEM_TESSERACT_CUBE_COMBINED', '2', [], [], None, '']
ok: CONST OEM_TESSERACT_CUBE_COMBINED=2

--- Incoming ---
[u'const cv.text.OEM_DEFAULT', '3', [], [], None, '']
ok: CONST OEM_DEFAULT=3

--- Incoming ---
[u'class cv.text.BaseOCR', '', [], [], None, '']
ok: class CLASS cv.text::.BaseOCR : , name: BaseOCR, base: 

--- Incoming ---
[   u'class cv.text.OCRTesseract',
    u': cv::text::BaseOCR',
    [],
    [],
    None,
    u'@brief OCRTesseract class provides an interface with the tesseract-ocr API (v3.02.02) in C++.\n\nNotice that it is compiled only when tesseract-ocr is correctly installed.\n\n@note\n-   (C++) An example of OCRTesseract recognition combined with scene text detection can be found\nat the end_to_end_recognition demo:\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/end_to_end_recognition.cpp>\n-   (C++) Another example of OCRTesseract recognition combined with scene text detection can be\nfound at the webcam_demo:\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp>']
ok: class CLASS cv.text::.OCRTesseract : BaseOCR, name: OCRTesseract, base: BaseOCR

--- Incoming ---
[   u'cv.text.OCRTesseract.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    u'@brief Recognize text using the tesseract-ocr API.\n\nTakes image on input and returns recognized text in the output_text parameter. Optionally\nprovides also the Rects for individual text elements found (e.g. words), and the list of those\ntext elements with their confidence values.\n\n@param image Input image CV_8UC1 or CV_8UC3\n@param output_text Output text of the tesseract-ocr.\n@param component_rects If provided the method will output a list of Rects for the individual\ntext elements found (e.g. words or text lines).\n@param component_texts If provided the method will output a list of text strings for the\nrecognition of individual text elements found (e.g. words or text lines).\n@param component_confidences If provided the method will output a list of confidence values\nfor the recognition of individual text elements found (e.g. words or text lines).\n@param component_level OCR_LEVEL_WORD (by default), or OCR_LEVEL_TEXTLINE.']
ok: FUNC <String cv.text.OCRTesseract.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRTesseract.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        ['Mat', u'mask', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    '']
ok: FUNC <String cv.text.OCRTesseract.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRTesseract.setWhiteList',
    u'void',
    ['/V', '/PV'],
    [[u'String', u'char_whitelist', u'', ['/C', '/Ref']]],
    u'void',
    '']
ok: FUNC <void cv.text.OCRTesseract.setWhiteList [ARG String char_whitelist=]>

--- Incoming ---
[   u'cv.text.OCRTesseract.create',
    u'Ptr_OCRTesseract',
    ['/S'],
    [   [u'c_string', u'datapath', u'0', ['/C']],
        [u'c_string', u'language', u'0', ['/C']],
        [u'c_string', u'char_whitelist', u'0', ['/C']],
        [u'int', u'oem', u'OEM_DEFAULT', []],
        [u'int', u'psmode', u'PSM_AUTO', []]],
    u'Ptr<OCRTesseract>',
    u'@brief Creates an instance of the OCRTesseract class. Initializes Tesseract.\n\n@param datapath the name of the parent directory of tessdata ended with "/", or NULL to use the\nsystem\'s default directory.\n@param language an ISO 639-3 code or NULL will default to "eng".\n@param char_whitelist specifies the list of characters used for recognition. NULL defaults to\n"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ".\n@param oem tesseract-ocr offers different OCR Engine Modes (OEM), by default\ntesseract::OEM_DEFAULT is used. See the tesseract-ocr API documentation for other possible\nvalues.\n@param psmode tesseract-ocr offers different Page Segmentation Modes (PSM) tesseract::PSM_AUTO\n(fully automatic layout analysis) is used. See the tesseract-ocr API documentation for other\npossible values.']
ok: FUNC <Ptr_OCRTesseract cv.text.OCRTesseract.create [ARG c_string datapath=0, ARG c_string language=0, ARG c_string char_whitelist=0, ARG int oem=OEM_DEFAULT, ARG int psmode=PSM_AUTO]>

--- Incoming ---
[u'const cv.text.OCR_DECODER_VITERBI', u'0', [], [], None, '']
ok: CONST OCR_DECODER_VITERBI=0

--- Incoming ---
[u'const cv.text.OCR_KNN_CLASSIFIER', u'0', [], [], None, '']
ok: CONST OCR_KNN_CLASSIFIER=0

--- Incoming ---
[u'const cv.text.OCR_CNN_CLASSIFIER', u'1', [], [], None, '']
ok: CONST OCR_CNN_CLASSIFIER=1

--- Incoming ---
[   u'class cv.text.OCRHMMDecoder',
    u': cv::text::BaseOCR',
    [],
    [],
    None,
    u'@brief OCRHMMDecoder class provides an interface for OCR using Hidden Markov Models.\n\n@note\n-   (C++) An example on using OCRHMMDecoder recognition combined with scene text detection can\nbe found at the webcam_demo sample:\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/webcam_demo.cpp>']
ok: class CLASS cv.text::.OCRHMMDecoder : BaseOCR, name: OCRHMMDecoder, base: BaseOCR

--- Incoming ---
[   u'class cv.text.OCRHMMDecoder.ClassifierCallback',
    '',
    [],
    [],
    None,
    u'@brief Callback with the character classifier is made a class.\n\nThis way it hides the feature extractor and the classifier itself, so developers can write\ntheir own OCR code.\n\nThe default character classifier and feature extractor can be loaded using the utility function\nloadOCRHMMClassifierNM and KNN model provided in\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/OCRHMM_knn_model_data.xml.gz>.']
ok: class CLASS cv.text::OCRHMMDecoder.ClassifierCallback : , name: ClassifierCallback, base: 

--- Incoming ---
[   u'cv.text.OCRHMMDecoder.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    u'@brief Recognize text using HMM.\n\nTakes an image and a mask (where each connected component corresponds to a segmented character)\non input and returns recognized text in the output_text parameter. Optionally\nprovides also the Rects for individual text elements found (e.g. words), and the list of those\ntext elements with their confidence values.\n\n@param image Input image CV_8UC1 or CV_8UC3 with a single text line (or word).\n@param mask Input binary image CV_8UC1 same size as input image. Each connected component in mask corresponds to a segmented character in the input image.\n\n@param output_text Output text. Most likely character sequence found by the HMM decoder.\n\n@param component_rects If provided the method will output a list of Rects for the individual\ntext elements found (e.g. words).\n\n@param component_texts If provided the method will output a list of text strings for the\nrecognition of individual text elements found (e.g. words).\n\n@param component_confidences If provided the method will output a list of confidence values\nfor the recognition of individual text elements found (e.g. words).\n\n@param component_level Only OCR_LEVEL_WORD is supported.']
ok: FUNC <String cv.text.OCRHMMDecoder.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRHMMDecoder.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        ['Mat', u'mask', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    '']
ok: FUNC <String cv.text.OCRHMMDecoder.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRHMMDecoder.create',
    u'Ptr_OCRHMMDecoder',
    ['/S'],
    [   [u'Ptr_OCRHMMDecoder_ClassifierCallback', u'classifier', u'', ['/C']],
        [u'String', u'vocabulary', u'', ['/C', '/Ref']],
        ['Mat', u'transition_probabilities_table', '', []],
        ['Mat', u'emission_probabilities_table', '', []],
        [u'int', u'mode', u'OCR_DECODER_VITERBI', []]],
    u'Ptr<OCRHMMDecoder>',
    u'@brief Creates an instance of the OCRHMMDecoder class. Initializes HMMDecoder.\n\n@param classifier The character classifier with built in feature extractor.\n\n@param vocabulary The language vocabulary (chars when ascii english text). vocabulary.size()\nmust be equal to the number of classes of the classifier.\n\n@param transition_probabilities_table Table with transition probabilities between character\npairs. cols == rows == vocabulary.size().\n\n@param emission_probabilities_table Table with observation emission probabilities. cols ==\nrows == vocabulary.size().\n\n@param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\n(<http://en.wikipedia.org/wiki/Viterbi_algorithm>).']
ok: FUNC <Ptr_OCRHMMDecoder cv.text.OCRHMMDecoder.create [ARG Ptr_OCRHMMDecoder_ClassifierCallback classifier=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI]>

--- Incoming ---
[   u'cv.text.OCRHMMDecoder.create',
    u'Ptr_OCRHMMDecoder',
    ['/S'],
    [   [u'String', u'filename', u'', ['/C', '/Ref']],
        [u'String', u'vocabulary', u'', ['/C', '/Ref']],
        ['Mat', u'transition_probabilities_table', '', []],
        ['Mat', u'emission_probabilities_table', '', []],
        [u'int', u'mode', u'OCR_DECODER_VITERBI', []],
        [u'int', u'classifier', u'OCR_KNN_CLASSIFIER', []]],
    u'Ptr<OCRHMMDecoder>',
    u'@brief Creates an instance of the OCRHMMDecoder class. Loads and initializes HMMDecoder from the specified path\n\n@overload']
ok: FUNC <Ptr_OCRHMMDecoder cv.text.OCRHMMDecoder.create [ARG String filename=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int classifier=OCR_KNN_CLASSIFIER]>

--- Incoming ---
[   u'cv.text.loadOCRHMMClassifierNM',
    u'Ptr_OCRHMMDecoder_ClassifierCallback',
    [],
    [[u'String', u'filename', u'', ['/C', '/Ref']]],
    u'Ptr<OCRHMMDecoder::ClassifierCallback>',
    u'@brief Allow to implicitly load the default character classifier when creating an OCRHMMDecoder object.\n\n@param filename The XML or YAML file with the classifier model (e.g. OCRHMM_knn_model_data.xml)\n\nThe KNN default classifier is based in the scene text recognition method proposed by Luk\xe1s Neumann &\nJiri Matas in [Neumann11b]. Basically, the region (contour) in the input image is normalized to a\nfixed size, while retaining the centroid and aspect ratio, in order to extract a feature vector\nbased on gradient orientations along the chain-code of its perimeter. Then, the region is classified\nusing a KNN model trained with synthetic data of rendered characters with different standard font\ntypes.\n\n@deprecated loadOCRHMMClassifier instead']
ok: FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifierNM [ARG String filename=]>

--- Incoming ---
[   u'cv.text.loadOCRHMMClassifierCNN',
    u'Ptr_OCRHMMDecoder_ClassifierCallback',
    [],
    [[u'String', u'filename', u'', ['/C', '/Ref']]],
    u'Ptr<OCRHMMDecoder::ClassifierCallback>',
    u'@brief Allow to implicitly load the default character classifier when creating an OCRHMMDecoder object.\n\n@param filename The XML or YAML file with the classifier model (e.g. OCRBeamSearch_CNN_model_data.xml.gz)\n\nThe CNN default classifier is based in the scene text recognition method proposed by Adam Coates &\nAndrew NG in [Coates11a]. The character classifier consists in a Single Layer Convolutional Neural Network and\na linear classifier. It is applied to the input image in a sliding window fashion, providing a set of recognitions\nat each window location.\n\n@deprecated use loadOCRHMMClassifier instead']
ok: FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifierCNN [ARG String filename=]>

--- Incoming ---
[   u'cv.text.loadOCRHMMClassifier',
    u'Ptr_OCRHMMDecoder_ClassifierCallback',
    [],
    [   [u'String', u'filename', u'', ['/C', '/Ref']],
        [u'int', u'classifier', u'', []]],
    u'Ptr<OCRHMMDecoder::ClassifierCallback>',
    u'@brief Allow to implicitly load the default character classifier when creating an OCRHMMDecoder object.\n\n@param filename The XML or YAML file with the classifier model (e.g. OCRBeamSearch_CNN_model_data.xml.gz)\n\n@param classifier Can be one of classifier_type enum values.']
ok: FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifier [ARG String filename=, ARG int classifier=]>

--- Incoming ---
[   u'cv.text.createOCRHMMTransitionsTable',
    u'Mat',
    [],
    [   [u'String', u'vocabulary', u'', ['/C', '/Ref']],
        [u'vector_String', u'lexicon', u'', ['/Ref']]],
    u'Mat',
    u'@brief Utility function to create a tailored language model transitions table from a given list of words (lexicon).\n*\n* @param vocabulary The language vocabulary (chars when ASCII English text).\n*\n* @param lexicon The list of words that are expected to be found in a particular image.\n*\n* @param transition_probabilities_table Output table with transition probabilities between character pairs. cols == rows == vocabulary.size().\n*\n* The function calculate frequency statistics of character pairs from the given lexicon and fills the output transition_probabilities_table with them. The transition_probabilities_table can be used as input in the OCRHMMDecoder::create() and OCRBeamSearchDecoder::create() methods.\n* @note\n*    -   (C++) An alternative would be to load the default generic language transition table provided in the text module samples folder (created from ispell 42869 english words list) :\n*            <https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/OCRHMM_transitions_table.xml>\n*']
ok: FUNC <Mat cv.text..createOCRHMMTransitionsTable [ARG String vocabulary=, ARG vector_String lexicon=]>

--- Incoming ---
[   u'class cv.text.OCRBeamSearchDecoder',
    u': cv::text::BaseOCR',
    [],
    [],
    None,
    u'@brief OCRBeamSearchDecoder class provides an interface for OCR using Beam Search algorithm.\n\n@note\n-   (C++) An example on using OCRBeamSearchDecoder recognition combined with scene text detection can\nbe found at the demo sample:\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/word_recognition.cpp>']
ok: class CLASS cv.text::.OCRBeamSearchDecoder : BaseOCR, name: OCRBeamSearchDecoder, base: BaseOCR

--- Incoming ---
[   u'class cv.text.OCRBeamSearchDecoder.ClassifierCallback',
    '',
    [],
    [],
    None,
    u'@brief Callback with the character classifier is made a class.\n\nThis way it hides the feature extractor and the classifier itself, so developers can write\ntheir own OCR code.\n\nThe default character classifier and feature extractor can be loaded using the utility funtion\nloadOCRBeamSearchClassifierCNN with all its parameters provided in\n<https://github.com/opencv/opencv_contrib/blob/master/modules/text/samples/OCRBeamSearch_CNN_model_data.xml.gz>.']
duplicated: CLASS cv.text::OCRBeamSearchDecoder.ClassifierCallback : 

--- Incoming ---
[   u'cv.text.OCRBeamSearchDecoder.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    u'@brief Recognize text using Beam Search.\n\nTakes image on input and returns recognized text in the output_text parameter. Optionally\nprovides also the Rects for individual text elements found (e.g. words), and the list of those\ntext elements with their confidence values.\n\n@param image Input binary image CV_8UC1 with a single text line (or word).\n\n@param output_text Output text. Most likely character sequence found by the HMM decoder.\n\n@param component_rects If provided the method will output a list of Rects for the individual\ntext elements found (e.g. words).\n\n@param component_texts If provided the method will output a list of text strings for the\nrecognition of individual text elements found (e.g. words).\n\n@param component_confidences If provided the method will output a list of confidence values\nfor the recognition of individual text elements found (e.g. words).\n\n@param component_level Only OCR_LEVEL_WORD is supported.']
ok: FUNC <String cv.text.OCRBeamSearchDecoder.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRBeamSearchDecoder.run',
    u'String',
    [],
    [   ['Mat', u'image', '', []],
        ['Mat', u'mask', '', []],
        [u'int', u'min_confidence', u'', []],
        [u'int', u'component_level', u'0', []]],
    u'String',
    '']
ok: FUNC <String cv.text.OCRBeamSearchDecoder.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>

--- Incoming ---
[   u'cv.text.OCRBeamSearchDecoder.create',
    u'Ptr_OCRBeamSearchDecoder',
    ['/S'],
    [   [   u'Ptr_OCRBeamSearchDecoder_ClassifierCallback',
            u'classifier',
            u'',
            ['/C']],
        [u'String', u'vocabulary', u'', ['/C', '/Ref']],
        ['Mat', u'transition_probabilities_table', '', []],
        ['Mat', u'emission_probabilities_table', '', []],
        [u'int', u'mode', u'OCR_DECODER_VITERBI', []],
        [u'int', u'beam_size', u'500', []]],
    u'Ptr<OCRBeamSearchDecoder>',
    u'@brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder.\n\n@param classifier The character classifier with built in feature extractor.\n\n@param vocabulary The language vocabulary (chars when ASCII English text). vocabulary.size()\nmust be equal to the number of classes of the classifier.\n\n@param transition_probabilities_table Table with transition probabilities between character\npairs. cols == rows == vocabulary.size().\n\n@param emission_probabilities_table Table with observation emission probabilities. cols ==\nrows == vocabulary.size().\n\n@param mode HMM Decoding algorithm. Only OCR_DECODER_VITERBI is available for the moment\n(<http://en.wikipedia.org/wiki/Viterbi_algorithm>).\n\n@param beam_size Size of the beam in Beam Search algorithm.']
ok: FUNC <Ptr_OCRBeamSearchDecoder cv.text.OCRBeamSearchDecoder.create [ARG Ptr_OCRBeamSearchDecoder_ClassifierCallback classifier=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int beam_size=500]>

--- Incoming ---
[   u'cv.text.OCRBeamSearchDecoder.create',
    u'Ptr_OCRBeamSearchDecoder',
    ['/S'],
    [   [u'String', u'filename', u'', ['/C', '/Ref']],
        [u'String', u'vocabulary', u'', ['/C', '/Ref']],
        ['Mat', u'transition_probabilities_table', '', []],
        ['Mat', u'emission_probabilities_table', '', []],
        [u'int', u'mode', u'OCR_DECODER_VITERBI', []],
        [u'int', u'beam_size', u'500', []]],
    u'Ptr<OCRBeamSearchDecoder>',
    u'@brief Creates an instance of the OCRBeamSearchDecoder class. Initializes HMMDecoder from the specified path.\n\n@overload']
ok: FUNC <Ptr_OCRBeamSearchDecoder cv.text.OCRBeamSearchDecoder.create [ARG String filename=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int beam_size=500]>

--- Incoming ---
[   u'cv.text.loadOCRBeamSearchClassifierCNN',
    u'Ptr_OCRBeamSearchDecoder_ClassifierCallback',
    [],
    [[u'String', u'filename', u'', ['/C', '/Ref']]],
    u'Ptr<OCRBeamSearchDecoder::ClassifierCallback>',
    u'@brief Allow to implicitly load the default character classifier when creating an OCRBeamSearchDecoder object.\n\n@param filename The XML or YAML file with the classifier model (e.g. OCRBeamSearch_CNN_model_data.xml.gz)\n\nThe CNN default classifier is based in the scene text recognition method proposed by Adam Coates &\nAndrew NG in [Coates11a]. The character classifier consists in a Single Layer Convolutional Neural Network and\na linear classifier. It is applied to the input image in a sliding window fashion, providing a set of recognitions\nat each window location.']
ok: FUNC <Ptr_OCRBeamSearchDecoder_ClassifierCallback cv.text..loadOCRBeamSearchClassifierCNN [ARG String filename=]>


===== Header: /Users/Chao/opencv_contrib/modules/text/include/opencv2/text/textDetector.hpp =====
Namespaces: set([u'cv.text', u'cv'])

--- Incoming ---
[   u'class cv.text.TextDetector',
    '',
    [],
    [],
    None,
    u'@brief An abstract class providing interface for text detection algorithms']
ok: class CLASS cv.text::.TextDetector : , name: TextDetector, base: 

--- Incoming ---
[   u'cv.text.TextDetector.detect',
    u'void',
    ['/V', '/PV'],
    [   ['Mat', u'inputImage', '', []],
        [u'vector_Rect', u'Bbox', u'', ['/O', '/Ref']],
        [u'vector_float', u'confidence', u'', ['/O', '/Ref']]],
    u'void',
    u'@brief Method that provides a quick and simple interface to detect text inside an image\n\n@param inputImage an image to process\n@param Bbox a vector of Rect that will store the detected word bounding box\n@param confidence a vector of float that will be updated with the confidence the classifier has for the selected bounding box']
ok: FUNC <void cv.text.TextDetector.detect [ARG Mat inputImage=, ARG vector_Rect Bbox=, ARG vector_float confidence=]>

--- Incoming ---
[   u'class cv.text.TextDetectorCNN',
    u': cv::text::TextDetector',
    [],
    [],
    None,
    u'@brief TextDetectorCNN class provides the functionallity of text bounding box detection.\nThis class is representing to find bounding boxes of text words given an input image.\nThis class uses OpenCV dnn module to load pre-trained model described in @cite LiaoSBWL17.\nThe original repository with the modified SSD Caffe version: https://github.com/MhLiao/TextBoxes.\nModel can be downloaded from [DropBox](https://www.dropbox.com/s/g8pjzv2de9gty8g/TextBoxes_icdar13.caffemodel?dl=0).\nModified .prototxt file with the model description can be found in `opencv_contrib/modules/text/samples/textbox.prototxt`.']
ok: class CLASS cv.text::.TextDetectorCNN : TextDetector, name: TextDetectorCNN, base: TextDetector

--- Incoming ---
[   u'cv.text.TextDetectorCNN.detect',
    u'void',
    ['/V', '/PV'],
    [   ['Mat', u'inputImage', '', []],
        [u'vector_Rect', u'Bbox', u'', ['/O', '/Ref']],
        [u'vector_float', u'confidence', u'', ['/O', '/Ref']]],
    u'void',
    u'@overload\n\n@param inputImage an image expected to be a CV_U8C3 of any size\n@param Bbox a vector of Rect that will store the detected word bounding box\n@param confidence a vector of float that will be updated with the confidence the classifier has for the selected bounding box']
ok: FUNC <void cv.text.TextDetectorCNN.detect [ARG Mat inputImage=, ARG vector_Rect Bbox=, ARG vector_float confidence=]>

--- Incoming ---
[   u'cv.text.TextDetectorCNN.create',
    u'Ptr_TextDetectorCNN',
    ['/S'],
    [   [u'String', u'modelArchFilename', u'', ['/C', '/Ref']],
        [u'String', u'modelWeightsFilename', u'', ['/C', '/Ref']]],
    u'Ptr<TextDetectorCNN>',
    u'@overload']
ok: FUNC <Ptr_TextDetectorCNN cv.text.TextDetectorCNN.create [ARG String modelArchFilename=, ARG String modelWeightsFilename=]>


===== Generating... =====
CLASS cv.text::OCRHMMDecoder.ClassifierCallback : 
CLASS cv.text::.BaseOCR : 
CLASS cv.text::.ERFilter : Algorithm
CLASS ::.Text : 
[CONST ERFILTER_NM_RGBLGrad=0, CONST ERFILTER_NM_IHSGrad=1, CONST ERGROUPING_ORIENTATION_HORIZ=0, CONST ERGROUPING_ORIENTATION_ANY=1, CONST OCR_LEVEL_WORD=0, CONST OCR_LEVEL_TEXTLINE=1, CONST PSM_OSD_ONLY=0, CONST PSM_AUTO_OSD=1, CONST PSM_AUTO_ONLY=2, CONST PSM_AUTO=3, CONST PSM_SINGLE_COLUMN=4, CONST PSM_SINGLE_BLOCK_VERT_TEXT=5, CONST PSM_SINGLE_BLOCK=6, CONST PSM_SINGLE_LINE=7, CONST PSM_SINGLE_WORD=8, CONST PSM_CIRCLE_WORD=9, CONST PSM_SINGLE_CHAR=10, CONST OEM_TESSERACT_ONLY=0, CONST OEM_CUBE_ONLY=1, CONST OEM_TESSERACT_CUBE_COMBINED=2, CONST OEM_DEFAULT=3, CONST OCR_DECODER_VITERBI=0, CONST OCR_KNN_CLASSIFIER=0, CONST OCR_CNN_CLASSIFIER=1]
FUNC <Mat cv.text..createOCRHMMTransitionsTable [ARG String vocabulary=, ARG vector_String lexicon=]>
java: Mat createOCRHMMTransitionsTable(String vocabulary, List<String> lexicon)
FUNC <Ptr_ERFilter cv.text..createERFilterNM1 [ARG Ptr_ERFilter_Callback cb=, ARG int thresholdDelta=1, ARG float minArea=(float)0.00025, ARG float maxArea=(float)0.13, ARG float minProbability=(float)0.4, ARG bool nonMaxSuppression=true, ARG float minProbabilityDiff=(float)0.1]>
SKIP:Ptr_ERFilter createERFilterNM1(Ptr_ERFilter_Callback cb, int thresholdDelta = 1, float minArea = (float)0.00025, float maxArea = (float)0.13, float minProbability = (float)0.4, bool nonMaxSuppression = true, float minProbabilityDiff = (float)0.1)	 due to ARG typePtr_ERFilter_Callback/I
FUNC <Ptr_ERFilter cv.text..createERFilterNM1 [ARG String filename=, ARG int thresholdDelta=1, ARG float minArea=(float)0.00025, ARG float maxArea=(float)0.13, ARG float minProbability=(float)0.4, ARG bool nonMaxSuppression=true, ARG float minProbabilityDiff=(float)0.1]>
java: ERFilter createERFilterNM1(String filename, int thresholdDelta, float minArea, float maxArea, float minProbability, boolean nonMaxSuppression, float minProbabilityDiff)
java: ERFilter createERFilterNM1(String filename)
FUNC <Ptr_ERFilter cv.text..createERFilterNM2 [ARG Ptr_ERFilter_Callback cb=, ARG float minProbability=(float)0.3]>
SKIP:Ptr_ERFilter createERFilterNM2(Ptr_ERFilter_Callback cb, float minProbability = (float)0.3)	 due to ARG typePtr_ERFilter_Callback/I
FUNC <Ptr_ERFilter cv.text..createERFilterNM2 [ARG String filename=, ARG float minProbability=(float)0.3]>
java: ERFilter createERFilterNM2(String filename, float minProbability)
java: ERFilter createERFilterNM2(String filename)
FUNC <Ptr_ERFilter_Callback cv.text..loadClassifierNM1 [ARG String filename=]>
SKIP:Ptr_ERFilter_Callback loadClassifierNM1(String filename)	 due to RET typePtr_ERFilter_Callback
FUNC <Ptr_ERFilter_Callback cv.text..loadClassifierNM2 [ARG String filename=]>
SKIP:Ptr_ERFilter_Callback loadClassifierNM2(String filename)	 due to RET typePtr_ERFilter_Callback
FUNC <Ptr_OCRBeamSearchDecoder_ClassifierCallback cv.text..loadOCRBeamSearchClassifierCNN [ARG String filename=]>
SKIP:Ptr_OCRBeamSearchDecoder_ClassifierCallback loadOCRBeamSearchClassifierCNN(String filename)	 due to RET typePtr_OCRBeamSearchDecoder_ClassifierCallback
FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifier [ARG String filename=, ARG int classifier=]>
SKIP:Ptr_OCRHMMDecoder_ClassifierCallback loadOCRHMMClassifier(String filename, int classifier)	 due to RET typePtr_OCRHMMDecoder_ClassifierCallback
FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifierCNN [ARG String filename=]>
SKIP:Ptr_OCRHMMDecoder_ClassifierCallback loadOCRHMMClassifierCNN(String filename)	 due to RET typePtr_OCRHMMDecoder_ClassifierCallback
FUNC <Ptr_OCRHMMDecoder_ClassifierCallback cv.text..loadOCRHMMClassifierNM [ARG String filename=]>
SKIP:Ptr_OCRHMMDecoder_ClassifierCallback loadOCRHMMClassifierNM(String filename)	 due to RET typePtr_OCRHMMDecoder_ClassifierCallback
FUNC <void cv.text..computeNMChannels [ARG Mat _src=, ARG vector_Mat _channels=, ARG int _mode=ERFILTER_NM_RGBLGrad]>
java: void computeNMChannels(Mat _src, List<Mat> _channels, int _mode)
java: void computeNMChannels(Mat _src, List<Mat> _channels)
FUNC <void cv.text..detectRegions [ARG Mat image=, ARG Ptr_ERFilter er_filter1=, ARG Ptr_ERFilter er_filter2=, ARG vector_Rect groups_rects=, ARG int method=ERGROUPING_ORIENTATION_HORIZ, ARG String filename=String(), ARG float minProbability=(float)0.5]>
java: void detectRegions(Mat image, ERFilter er_filter1, ERFilter er_filter2, MatOfRect groups_rects, int method, String filename, float minProbability)
java: void detectRegions(Mat image, ERFilter er_filter1, ERFilter er_filter2, MatOfRect groups_rects)
FUNC <void cv.text..detectRegions [ARG Mat image=, ARG Ptr_ERFilter er_filter1=, ARG Ptr_ERFilter er_filter2=, ARG vector_vector_Point regions=]>
java: void detectRegions(Mat image, ERFilter er_filter1, ERFilter er_filter2, List<MatOfPoint> regions)
FUNC <void cv.text..erGrouping [ARG Mat image=, ARG Mat channel=, ARG vector_vector_Point regions=, ARG vector_Rect groups_rects=, ARG int method=ERGROUPING_ORIENTATION_HORIZ, ARG String filename=String(), ARG float minProbablity=(float)0.5]>
java: void erGrouping(Mat image, Mat channel, List<MatOfPoint> regions, MatOfRect groups_rects, int method, String filename, float minProbablity)
java: void erGrouping(Mat image, Mat channel, List<MatOfPoint> regions, MatOfRect groups_rects)
CLASS cv.text::.OCRBeamSearchDecoder : BaseOCR
FUNC <Ptr_OCRBeamSearchDecoder cv.text.OCRBeamSearchDecoder.create [ARG Ptr_OCRBeamSearchDecoder_ClassifierCallback classifier=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int beam_size=500]>
SKIP:static Ptr_OCRBeamSearchDecoder create(Ptr_OCRBeamSearchDecoder_ClassifierCallback classifier, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table, int mode = OCR_DECODER_VITERBI, int beam_size = 500)	 due to ARG typePtr_OCRBeamSearchDecoder_ClassifierCallback/I
FUNC <Ptr_OCRBeamSearchDecoder cv.text.OCRBeamSearchDecoder.create [ARG String filename=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int beam_size=500]>
java: OCRBeamSearchDecoder create(String filename, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table, int mode, int beam_size)
java: OCRBeamSearchDecoder create(String filename, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table)
FUNC <String cv.text.OCRBeamSearchDecoder.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, Mat mask, int min_confidence, int component_level)
java: String run(Mat image, Mat mask, int min_confidence)
FUNC <String cv.text.OCRBeamSearchDecoder.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, int min_confidence, int component_level)
java: String run(Mat image, int min_confidence)
CLASS cv.text::ERFilter.Callback : 
CLASS cv.text::.TextDetector : 
FUNC <void cv.text.TextDetector.detect [ARG Mat inputImage=, ARG vector_Rect Bbox=, ARG vector_float confidence=]>
java: void detect(Mat inputImage, MatOfRect Bbox, MatOfFloat confidence)
CLASS cv.text::.OCRTesseract : BaseOCR
FUNC <Ptr_OCRTesseract cv.text.OCRTesseract.create [ARG c_string datapath=0, ARG c_string language=0, ARG c_string char_whitelist=0, ARG int oem=OEM_DEFAULT, ARG int psmode=PSM_AUTO]>
java: OCRTesseract create(String datapath, String language, String char_whitelist, int oem, int psmode)
java: OCRTesseract create()
FUNC <String cv.text.OCRTesseract.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, Mat mask, int min_confidence, int component_level)
java: String run(Mat image, Mat mask, int min_confidence)
FUNC <String cv.text.OCRTesseract.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, int min_confidence, int component_level)
java: String run(Mat image, int min_confidence)
FUNC <void cv.text.OCRTesseract.setWhiteList [ARG String char_whitelist=]>
java: void setWhiteList(String char_whitelist)
CLASS cv.text::.OCRHMMDecoder : BaseOCR
FUNC <Ptr_OCRHMMDecoder cv.text.OCRHMMDecoder.create [ARG Ptr_OCRHMMDecoder_ClassifierCallback classifier=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI]>
SKIP:static Ptr_OCRHMMDecoder create(Ptr_OCRHMMDecoder_ClassifierCallback classifier, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table, int mode = OCR_DECODER_VITERBI)	 due to ARG typePtr_OCRHMMDecoder_ClassifierCallback/I
FUNC <Ptr_OCRHMMDecoder cv.text.OCRHMMDecoder.create [ARG String filename=, ARG String vocabulary=, ARG Mat transition_probabilities_table=, ARG Mat emission_probabilities_table=, ARG int mode=OCR_DECODER_VITERBI, ARG int classifier=OCR_KNN_CLASSIFIER]>
java: OCRHMMDecoder create(String filename, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table, int mode, int classifier)
java: OCRHMMDecoder create(String filename, String vocabulary, Mat transition_probabilities_table, Mat emission_probabilities_table)
FUNC <String cv.text.OCRHMMDecoder.run [ARG Mat image=, ARG Mat mask=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, Mat mask, int min_confidence, int component_level)
java: String run(Mat image, Mat mask, int min_confidence)
FUNC <String cv.text.OCRHMMDecoder.run [ARG Mat image=, ARG int min_confidence=, ARG int component_level=0]>
java: String run(Mat image, int min_confidence, int component_level)
java: String run(Mat image, int min_confidence)
CLASS cv.text::.TextDetectorCNN : TextDetector
FUNC <Ptr_TextDetectorCNN cv.text.TextDetectorCNN.create [ARG String modelArchFilename=, ARG String modelWeightsFilename=]>
java: TextDetectorCNN create(String modelArchFilename, String modelWeightsFilename)
FUNC <void cv.text.TextDetectorCNN.detect [ARG Mat inputImage=, ARG vector_Rect Bbox=, ARG vector_float confidence=]>
java: void detect(Mat inputImage, MatOfRect Bbox, MatOfFloat confidence)
